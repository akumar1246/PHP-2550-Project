---
title: "Variables Description" 
author: "Anusha Kumar, Kyla Finlayson, Nataliya Kyrychenko"
date: "2022-10-18"
output:
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE)

#Load packages
library(tidyverse)
library(kableExtra)
library(gridExtra)
library(tableone)
library(lubridate)
library(anytime)
library(gridExtra)
library(stringr)

#Read in data
isolates <- read.csv("~/Desktop/isolates.csv", na.strings=c("","NA"))
```

### **Data Description**

In this study, secondary data is used for Campylobacter jejuni, taken from the "Isolates" browser of the National Library of Medicine's (NIH) NCBI Pathogen Detection Project.

This public repository is widely used by public health practitioners and researchers, both at international, federal, and state levels. It helps to match foodborne pathogens that became source of clinical cases around the US, and even the whole world through clustering of related isolates. It also helps to investigate outbreaks, research prevalence of strains, AMR and virulence genes. There are other types of use of NCBI Pathogen Detection database both by public health practitioners and researchers. For example, the database is used for international outbreaks investigation, connecting clinical and environmental isolates in Canada, USA, France, Australia, and South Korea. Except outbreak detection, the database is used for analysis of distribution of pathogens throughout the world, including specific virulent genes, AMR-resistant genes, analysis of prevalence of certain genomic sequence.

For our project, we will be using a specific subset of the databse which contains isolates of Campylobacter jejuni. Our initial dataset has 80095 observations, 19 variables, and can be located at:
https://www.ncbi.nlm.nih.gov/pathogens/isolates/#taxgroup_name:%22Campylobacter%20jejuni%22. The default dataset has 16 main variables, with the option to add other variables. We have decided to add three variables: 'Collection.date', "Outbreak', and 'Host disease' as we believe these could potentially be useful in our analysis.

### **Data Overview**


### **Data Cleaning**

Before we begin exploring our data, there are a few variables we would like to create. After conducting a brief initial exploration of our data, there were a few variables that require cleaning and/or regrouping. 

We first noticed that one of our variables of interest, *Collection.date*, usually contains the year of collection but is often missing the month and/or the day of isolate collection. As a result, we will create a two new variables called *Year* and *Month* which contain the collection year and month, respectively, when it is available. When collection year is not available, it will use the creation year (when it is uploaded into the data base). The same applies for month as well. From our exploration, we saw that creation date is usually relatively close to collection date, however, our variable will be more accurate if we utilize the correct information that we do have. We will use these two variables as our time variables for analysis rather than using *Collection.date* or *Create.date*.

```{r}
# Year

  # Convert all dates to the same Y-M-D format, those that do not have
  # years will return as NA and we can fill in year from Create.date
isolates$Collection.date2 <- anydate(isolates$Collection.date)

  # Parse the year
isolates$Year <- format(as.Date(isolates$Collection.date2, 
                                format = "%Y-%m-%d"), "%Y")

  # Fill in NA values with year from Create.date
isolates$Year <- ifelse(is.na(isolates$Year),
                        format(as.Date(isolates$Create.date), "%Y"),
                        isolates$Year)

# Month

  # Convert all dates to the same Y-M format, those that do not have
  # months will return as NA and we can fill in month from Create.date
isolates$Collection.date2 <- ym(isolates$Collection.date)

  # Parse the month
isolates$Month <- format(as.Date(isolates$Collection.date2,
                                 format = "%Y-%m-%d"), "%m")

  # Fill in NA values with month from Create.date
isolates$Month <- ifelse(is.na(isolates$Month),
                        format(as.Date(isolates$Create.date), "%m"),
                        isolates$Month)

# Remove Create.date and Collection.date, as they are no longer needed
isolates <- isolates %>%
  select(-c(Year, Month))
```

Next, we noticed that another one of our variables of interest, *Isolation.source*, is very messy. Because this variable is sourced from text input, each category has many different variations based on terms used, capitalization, punctuation, etc. For example, "Raw chicken meat", "raw chicken", and "chicken wings" pretty much all have the same meaning, but they are considered different categories. There are a total of 657 different categories in our data for this variable. As a result, we are going to look at the most frequently used words in *Isolation.source* and create new categories based on these. In the example I gave above, all three examples would go under a category like "chicken" or "chicken meat".

```{r, eval=FALSE}
  # First, we will need to remove all punctuation and make all letters
  # lowercase
isolates$Isolation.source <- isolates$Isolation.source %>%
  str_to_lower() %>%
  str_replace_all("[:punct:]", " ")

  # Now we will split each entry into its respective words and look
  # at the most frequently used terms
sort(table(unlist(strsplit(isolates$Isolation.source, " "))), decreasing=TRUE)
```

Some of our most frequently used keywords include "chicken", "animal", "raw", "stool", "carcass", "cattle" and "human". One important thing here is that we do not want to confuse exposure from chicken meat with exposure from chicken as an animal. Using the keyword "animal" as well as our general knowledge of other terms and Campylobacter sources, we can regroup this variable to include the most common isolation sources, and have a bucket for the unusual/less common ones called "Other".


```{r}


isolates <- isolates %>%
  mutate(Isolation.source = case_when(str_detect(Isolation.source, "animal") &
                                      str_detect(Isolation.source, "chicken") |
                                      str_detect(Isolation.source, "chicken") &
                                      str_detect(Isolation.source, "carcass") |
                                      str_detect(Isolation.source, "gallus") |
                                      str_detect(Isolation.source, "cecal") |
                                      str_detect(Isolation.source, "caecum") |
                                      str_detect(Isolation.source, "caeca") |
                                      str_detect(Isolation.source, "cecum") ~ "Animal: Chicken",
                                      str_detect(Isolation.source, "chicken") | 
                                      str_detect(Isolation.source, "wings") |
                                      str_detect(Isolation.source, "thighs") ~ "Meat: Chicken",
                                      str_detect(Isolation.source, "cattle") | 
                                      str_detect(Isolation.source, "cow") |
                                      str_detect(Isolation.source, "bovine") |
                                      str_detect(Isolation.source, "steer") ~ "Animal: Cattle")
                                        )





```


### **Missing Data**

```{r, echo=FALSE, warning=FALSE, fig.height=3, fig.width=7, fig.cap = "Percentage of Missing Values"}

## The code below is from a code demo we went over in class and can also be
## found at https://jenslaufer.com/data/analysis/visualize_missing_values_with_ggplot.html

#Calculating the percentages of missing values by variable
missing.values <- isolates %>%
  gather(key = "key", value = "val") %>%
  mutate(isna = is.na(val)) %>%
  group_by(key) %>%
  mutate(total = n()) %>%
  group_by(key, total, isna) %>%
  summarise(num.isna = n()) %>%
  mutate(pct = num.isna / total * 100)

#Limiting to only variables that have NA values and arranging in descending order
levels <- (missing.values %>% filter(isna == T) %>%     
             arrange(desc(pct)))$key

#Plotting missing values by variable
percentage.plot <- missing.values %>%
  ggplot() +
  geom_bar(aes(x = reorder(key, desc(pct)), 
               y = pct, fill=isna), 
           stat = 'identity', alpha=0.8) +
  scale_x_discrete(limits = levels) +
  scale_fill_manual(name = "", 
                    values = c('steelblue', 'tomato3'), 
                    labels = c("Present", "Missing")) +
  coord_flip() +
  labs(x = 'Variable', y = "% of missing values")

percentage.plot
```

As we can see in Figure 1, a few of our variables have an extremely high percentage of missing values. Source.type, Virulence.genotypes, Outbreak, PFGE.secondary.enzyme.pattern, PFGE.primary.enzyme.pattern, Lat.Lon, IFSAC.category, Host.disease, and Host all have greater than 75% of values missing. As a result, we will need to determine whether or not these variables tell us any useful information. If there are no differences between observations that have missing values and observations that do not have missing values for a specific variable, then we will remove that variable. We will keep variables that have less than 50% missing values because we may be able to conduct multiple imputation for these. First, we begin by removing "Source.type" because 100% of our values are missing for this variable and "Virulence.genotypes" because all of our values except for two are missing. Then, we will look at each variable that has more than 50% of values missing and determine if there are significant differences in any variables, using a Chi-square test for categorical variables and a T-test for continuous variables, between those who have missing observations and those who do not.

```{r, echo=FALSE, warning=FALSE, fig.height=3, fig.width=7, fig.cap="Missing Values by Row"}

## The code below is from a code demo we went over in class and can also be
## found at https://jenslaufer.com/data/analysis/visualize_missing_values_with_ggplot.html

#Selecting only our continuous variables and visualizing missingness by row number
row.plot <- isolates %>%
  mutate(id = row_number()) %>%
  gather(-id, key = "key", value = "val") %>%
  mutate(isna = is.na(val)) %>%
  ggplot(aes(key, id, fill = isna)) +
  geom_raster(alpha=0.8) +
  scale_fill_manual(name = "",
                    values = c('steelblue', 'tomato3'),
                    labels = c("Present", "Missing")) +
  scale_x_discrete(limits = levels) +
  labs(x = "Variable",
       y = "Row Number") +
  coord_flip()

row.plot
```



Next, we will have to define our outcome of interest, Outbreak because the "Outbreak" variable that came with our dataset is 99% missing.

```{r, echo=FALSE}
isolates <- isolates %>%
  mutate(Outbreak = case_when())

```
